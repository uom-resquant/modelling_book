<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Regression I: Mean differences | Modelling Criminological Data CRIM20452</title>
  <meta name="description" content="This is the course material for Modelling Criminological Data CRIM20452." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Regression I: Mean differences | Modelling Criminological Data CRIM20452" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the course material for Modelling Criminological Data CRIM20452." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Regression I: Mean differences | Modelling Criminological Data CRIM20452" />
  
  <meta name="twitter:description" content="This is the course material for Modelling Criminological Data CRIM20452." />
  

<meta name="author" content="" />


<meta name="date" content="2025-03-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="refresher-on-descriptive-statistics-data-carpentry.html"/>
<link rel="next" href="regression-ii-numerical-independent-variables.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelling Criminological Data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html"><i class="fa fa-check"></i><b>1</b> A first lesson about R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#install-r-rstudio"><i class="fa fa-check"></i><b>1.1</b> Install R &amp; RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#open-up-and-explore-rstudio"><i class="fa fa-check"></i><b>1.2</b> Open up and explore RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#customising-the-rstudio-look"><i class="fa fa-check"></i><b>1.3</b> Customising the RStudio look</a></li>
<li class="chapter" data-level="1.4" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#getting-organised-r-projects"><i class="fa fa-check"></i><b>1.4</b> Getting organised: R Projects</a></li>
<li class="chapter" data-level="1.5" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#functions-talk-to-your-computer"><i class="fa fa-check"></i><b>1.5</b> Functions: Talk to your computer</a></li>
<li class="chapter" data-level="1.6" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#more-on-packages"><i class="fa fa-check"></i><b>1.6</b> More on packages</a></li>
<li class="chapter" data-level="1.7" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#objects-creating-an-object"><i class="fa fa-check"></i><b>1.7</b> Objects: creating an object</a></li>
<li class="chapter" data-level="1.8" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#more-on-objects"><i class="fa fa-check"></i><b>1.8</b> More on objects</a></li>
<li class="chapter" data-level="1.9" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#naming-conventions-for-objects-in-r"><i class="fa fa-check"></i><b>1.9</b> Naming conventions for objects in R</a></li>
<li class="chapter" data-level="1.10" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#r-object-types-vectors"><i class="fa fa-check"></i><b>1.10</b> R object types: vectors</a></li>
<li class="chapter" data-level="1.11" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#r-object-types-data-frame"><i class="fa fa-check"></i><b>1.11</b> R object types: Data frame</a></li>
<li class="chapter" data-level="1.12" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#exploring-data"><i class="fa fa-check"></i><b>1.12</b> Exploring data</a></li>
<li class="chapter" data-level="1.13" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#r-data-types-factors"><i class="fa fa-check"></i><b>1.13</b> R data types: Factors</a></li>
<li class="chapter" data-level="1.14" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#how-to-import-data"><i class="fa fa-check"></i><b>1.14</b> How to import data</a></li>
<li class="chapter" data-level="1.15" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#how-to-use-comment"><i class="fa fa-check"></i><b>1.15</b> How to use ‘comment’</a></li>
<li class="chapter" data-level="1.16" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#how-to-quit-rstudio"><i class="fa fa-check"></i><b>1.16</b> How to Quit RStudio</a></li>
<li class="chapter" data-level="1.17" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#summary"><i class="fa fa-check"></i><b>1.17</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html"><i class="fa fa-check"></i><b>2</b> Getting to know your data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#causality-in-social-sciences"><i class="fa fa-check"></i><b>2.1</b> Causality in Social Sciences</a></li>
<li class="chapter" data-level="2.2" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#getting-data-thanks-to-reproducibility"><i class="fa fa-check"></i><b>2.2</b> Getting data thanks to reproducibility</a></li>
<li class="chapter" data-level="2.3" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#getting-a-sense-of-your-data"><i class="fa fa-check"></i><b>2.3</b> Getting a sense of your data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#first-steps"><i class="fa fa-check"></i><b>2.3.1</b> First steps</a></li>
<li class="chapter" data-level="2.3.2" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#on-tibbles-and-labelled-vectors"><i class="fa fa-check"></i><b>2.3.2</b> On tibbles and labelled vectors</a></li>
<li class="chapter" data-level="2.3.3" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#turning-variables-into-factors-and-changing-the-labels"><i class="fa fa-check"></i><b>2.3.3</b> Turning variables into factors and changing the labels</a></li>
<li class="chapter" data-level="2.3.4" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#looking-for-missing-data-and-other-anomalies"><i class="fa fa-check"></i><b>2.3.4</b> Looking for missing data and other anomalies</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#data-wrangling-with-dplyr"><i class="fa fa-check"></i><b>2.4</b> Data wrangling with dplyr</a></li>
<li class="chapter" data-level="2.5" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#using-dplyr-single-verbs"><i class="fa fa-check"></i><b>2.5</b> Using dplyr single verbs</a></li>
<li class="chapter" data-level="2.6" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#using-dplyr-for-grouped-operations"><i class="fa fa-check"></i><b>2.6</b> Using dplyr for grouped operations</a></li>
<li class="chapter" data-level="2.7" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#making-comparisons-with-numerical-outcomes"><i class="fa fa-check"></i><b>2.7</b> Making comparisons with numerical outcomes</a></li>
<li class="chapter" data-level="2.8" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#summary-1"><i class="fa fa-check"></i><b>2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html"><i class="fa fa-check"></i><b>3</b> Data visualisation with R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#anatomy-of-a-plot"><i class="fa fa-check"></i><b>3.2</b> Anatomy of a plot</a></li>
<li class="chapter" data-level="3.3" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#what-graph-should-i-use"><i class="fa fa-check"></i><b>3.3</b> What graph should I use?</a></li>
<li class="chapter" data-level="3.4" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#visualising-numerical-variables-histograms"><i class="fa fa-check"></i><b>3.4</b> Visualising numerical variables: Histograms</a></li>
<li class="chapter" data-level="3.5" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#visualising-numerical-variables-density-plots"><i class="fa fa-check"></i><b>3.5</b> Visualising numerical variables: Density plots</a></li>
<li class="chapter" data-level="3.6" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#visualising-numerical-variables-box-plots"><i class="fa fa-check"></i><b>3.6</b> Visualising numerical variables: Box plots</a></li>
<li class="chapter" data-level="3.7" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#exploring-relationships-between-two-quantitative-variables-scatterplots"><i class="fa fa-check"></i><b>3.7</b> Exploring relationships between two quantitative variables: scatterplots</a></li>
<li class="chapter" data-level="3.8" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#scatterplots-conditioning-in-a-third-variable"><i class="fa fa-check"></i><b>3.8</b> Scatterplots conditioning in a third variable</a></li>
<li class="chapter" data-level="3.9" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#scatterplot-matrix"><i class="fa fa-check"></i><b>3.9</b> Scatterplot matrix</a></li>
<li class="chapter" data-level="3.10" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#titles-legends-and-themes-in-ggplot2"><i class="fa fa-check"></i><b>3.10</b> Titles, legends, and themes in ggplot2</a></li>
<li class="chapter" data-level="3.11" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#plotting-categorical-data-bar-charts"><i class="fa fa-check"></i><b>3.11</b> Plotting categorical data: bar charts</a></li>
<li class="chapter" data-level="3.12" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#further-resources"><i class="fa fa-check"></i><b>3.12</b> Further resources</a></li>
<li class="chapter" data-level="3.13" data-path="data-visualisation-with-r.html"><a href="data-visualisation-with-r.html#summary-2"><i class="fa fa-check"></i><b>3.13</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html"><i class="fa fa-check"></i><b>4</b> Refresher on descriptive statistics &amp; data carpentry</a>
<ul>
<li class="chapter" data-level="4.1" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#getting-some-data-from-eurobarometer"><i class="fa fa-check"></i><b>4.2</b> Getting some data from Eurobarometer</a></li>
<li class="chapter" data-level="4.3" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#thinking-about-your-data-filtering-cases"><i class="fa fa-check"></i><b>4.3</b> Thinking about your data: filtering cases</a></li>
<li class="chapter" data-level="4.4" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#selecting-variables-using-dplyrselect"><i class="fa fa-check"></i><b>4.4</b> Selecting variables: using <code>dplyr::select</code></a></li>
<li class="chapter" data-level="4.5" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#creating-summated-scales"><i class="fa fa-check"></i><b>4.5</b> Creating summated scales</a></li>
<li class="chapter" data-level="4.6" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#collapsing-categories-in-character-variables"><i class="fa fa-check"></i><b>4.6</b> Collapsing categories in character variables</a></li>
<li class="chapter" data-level="4.7" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#working-with-apparently-cryptic-variable-names-and-levels"><i class="fa fa-check"></i><b>4.7</b> Working with apparently cryptic variable names and levels</a></li>
<li class="chapter" data-level="4.8" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#recoding-factors"><i class="fa fa-check"></i><b>4.8</b> Recoding factors</a></li>
<li class="chapter" data-level="4.9" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#understanding-missing-data"><i class="fa fa-check"></i><b>4.9</b> Understanding missing data</a></li>
<li class="chapter" data-level="4.10" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#exploring-data-frames-visually"><i class="fa fa-check"></i><b>4.10</b> Exploring data frames visually</a></li>
<li class="chapter" data-level="4.11" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#a-quick-recap-on-descriptive-statistics"><i class="fa fa-check"></i><b>4.11</b> A quick recap on descriptive statistics</a>
<ul>
<li class="chapter" data-level="4.11.1" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#central-tendency"><i class="fa fa-check"></i><b>4.11.1</b> Central Tendency</a></li>
<li class="chapter" data-level="4.11.2" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#dispersion"><i class="fa fa-check"></i><b>4.11.2</b> Dispersion</a></li>
<li class="chapter" data-level="4.11.3" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#bivariate-analysis"><i class="fa fa-check"></i><b>4.11.3</b> Bivariate analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#further-resources-1"><i class="fa fa-check"></i><b>4.12</b> Further resources</a></li>
<li class="chapter" data-level="4.13" data-path="refresher-on-descriptive-statistics-data-carpentry.html"><a href="refresher-on-descriptive-statistics-data-carpentry.html#summary-3"><i class="fa fa-check"></i><b>4.13</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html"><i class="fa fa-check"></i><b>5</b> Regression I: Mean differences</a>
<ul>
<li class="chapter" data-level="5.1" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#introduction-2"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#dependent-variable-numerical-independent-variable-binary"><i class="fa fa-check"></i><b>5.2</b> Dependent variable: numerical | Independent variable: binary</a></li>
<li class="chapter" data-level="5.3" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#calculating-mean-differences-in-r"><i class="fa fa-check"></i><b>5.3</b> Calculating mean differences in <code>R</code></a></li>
<li class="chapter" data-level="5.4" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#visual-exploration"><i class="fa fa-check"></i><b>5.4</b> Visual exploration</a></li>
<li class="chapter" data-level="5.5" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#using-linear-regression-to-calculate-mean-differences"><i class="fa fa-check"></i><b>5.5</b> Using linear regression to calculate mean differences</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#linear-regression"><i class="fa fa-check"></i><b>5.5.1</b> Linear Regression</a></li>
<li class="chapter" data-level="5.5.2" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#linear-regression-as-a-difference-in-means-estimator"><i class="fa fa-check"></i><b>5.5.2</b> Linear Regression as a Difference-in-Means Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#effect-size"><i class="fa fa-check"></i><b>5.6</b> Effect size</a></li>
<li class="chapter" data-level="5.7" data-path="regression-i-mean-differences.html"><a href="regression-i-mean-differences.html#lab-exercises"><i class="fa fa-check"></i><b>5.7</b> Lab Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html"><i class="fa fa-check"></i><b>6</b> Regression II: numerical independent variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#motivating-regression"><i class="fa fa-check"></i><b>6.2</b> Motivating regression</a></li>
<li class="chapter" data-level="6.3" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>6.3</b> Fitting a simple regression model</a></li>
<li class="chapter" data-level="6.4" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#residuals-r-squared"><i class="fa fa-check"></i><b>6.4</b> Residuals: R squared</a></li>
<li class="chapter" data-level="6.5" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#is-this-the-same-as-last-week"><i class="fa fa-check"></i><b>6.5</b> Is this the same as last week?</a></li>
<li class="chapter" data-level="6.6" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#regression-assumptions"><i class="fa fa-check"></i><b>6.6</b> Regression assumptions</a></li>
<li class="chapter" data-level="6.7" data-path="regression-ii-numerical-independent-variables.html"><a href="regression-ii-numerical-independent-variables.html#lab-exercises-1"><i class="fa fa-check"></i><b>6.7</b> Lab Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><i class="fa fa-check"></i><b>7</b> Regression III: categorical independent variables and multiple regression models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html#fitting-regression-with-categorical-predictors"><i class="fa fa-check"></i><b>7.1</b> Fitting regression with categorical predictors</a></li>
<li class="chapter" data-level="7.2" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html#motivating-multiple-regression"><i class="fa fa-check"></i><b>7.2</b> Motivating multiple regression</a></li>
<li class="chapter" data-level="7.3" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html#fitting-and-interpreting-a-multiple-regression-model"><i class="fa fa-check"></i><b>7.3</b> Fitting and interpreting a multiple regression model</a></li>
<li class="chapter" data-level="7.4" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html#rescaling-input-variables-to-assist-interpretation"><i class="fa fa-check"></i><b>7.4</b> Rescaling input variables to assist interpretation</a></li>
<li class="chapter" data-level="7.5" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html#testing-conditional-hypothesis-interactions"><i class="fa fa-check"></i><b>7.5</b> Testing conditional hypothesis: interactions</a></li>
<li class="chapter" data-level="7.6" data-path="regression-iii-categorical-independent-variables-and-multiple-regression-models.html"><a href="regression-iii-categorical-independent-variables-and-multiple-regression-models.html#multicollinearity"><i class="fa fa-check"></i><b>7.6</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Categorical variables and logistic regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#cross-tabulations"><i class="fa fa-check"></i><b>8.1</b> Cross-tabulations</a></li>
<li class="chapter" data-level="8.2" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#regression-modelling-why-not-linear-regression"><i class="fa fa-check"></i><b>8.2</b> Regression modelling: why not linear regression?</a></li>
<li class="chapter" data-level="8.3" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#logistic-regression"><i class="fa fa-check"></i><b>8.3</b> Logistic regression</a></li>
<li class="chapter" data-level="8.4" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#fitting-logistic-regression"><i class="fa fa-check"></i><b>8.4</b> Fitting logistic regression</a></li>
<li class="chapter" data-level="8.5" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#interactions"><i class="fa fa-check"></i><b>8.5</b> Interactions</a></li>
<li class="chapter" data-level="8.6" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#assessing-model-fit-confusion-matrix"><i class="fa fa-check"></i><b>8.6</b> Assessing model fit: confusion matrix</a></li>
<li class="chapter" data-level="8.7" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#lab-exercises-2"><i class="fa fa-check"></i><b>8.7</b> Lab Exercises</a></li>
<li class="chapter" data-level="8.8" data-path="categorical-variables-and-logistic-regression.html"><a href="categorical-variables-and-logistic-regression.html#further-resources-2"><i class="fa fa-check"></i><b>8.8</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>9</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="9.1" data-path="statistical-inference.html"><a href="statistical-inference.html#introduction-4"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="statistical-inference.html"><a href="statistical-inference.html#brief-theoretical-overview"><i class="fa fa-check"></i><b>9.2</b> Brief theoretical overview</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#sampling-distribution-central-limit-theorem"><i class="fa fa-check"></i>Sampling distribution &amp; Central limit theorem</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-confidence-intervals"><i class="fa fa-check"></i>Statistical inference: confidence intervals</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-hypothesis-testing"><i class="fa fa-check"></i>Statistical inference: hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-in-practice"><i class="fa fa-check"></i><b>9.3</b> Statistical inference in practice</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#means-and-proportions"><i class="fa fa-check"></i>Means and proportions</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-in-linear-regression-models"><i class="fa fa-check"></i>Statistical inference in linear regression models</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-in-multiple-linear-regression-models"><i class="fa fa-check"></i>Statistical inference in multiple linear regression models</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#presenting-results-from-regression-analysis"><i class="fa fa-check"></i>Presenting results from regression analysis</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-in-logistic-regression-models"><i class="fa fa-check"></i>Statistical inference in logistic regression models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="wrapping-up.html"><a href="wrapping-up.html"><i class="fa fa-check"></i><b>10</b> Wrapping up</a></li>
<li class="chapter" data-level="11" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>11</b> Appendix</a>
<ul>
<li class="chapter" data-level="11.0.1" data-path="appendix.html"><a href="appendix.html#expected-frequencies"><i class="fa fa-check"></i><b>11.0.1</b> Expected frequencies</a></li>
<li class="chapter" data-level="11.1" data-path="appendix.html"><a href="appendix.html#logistic-regression-1"><i class="fa fa-check"></i><b>11.1</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="appendix.html"><a href="appendix.html#fitting-logistic-regression-alternative"><i class="fa fa-check"></i><b>11.1.1</b> Fitting logistic regression: alternative</a></li>
<li class="chapter" data-level="11.1.2" data-path="appendix.html"><a href="appendix.html#assessing-model-fit-deviance-and-pseudo-r-squared"><i class="fa fa-check"></i><b>11.1.2</b> Assessing model fit: deviance and pseudo r squared</a></li>
<li class="chapter" data-level="11.1.3" data-path="appendix.html"><a href="appendix.html#assessing-model-fit-roc-curves"><i class="fa fa-check"></i><b>11.1.3</b> Assessing model fit: ROC curves</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelling Criminological Data CRIM20452</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-i-mean-differences" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Regression I: Mean differences<a href="regression-i-mean-differences.html#regression-i-mean-differences" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-2" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction<a href="regression-i-mean-differences.html#introduction-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Up to now we have introduced a series of concepts and tools that help describe variables. Descriptive statistics are crucial for summarising information about individual variables. However, in the social sciences, we often aim to go beyond description. We use data to test theories, investigate relationships, and uncover associations. This requires moving beyond single-variable analysis to examining the relationship between two variables. In this chapter, we begin exploring bivariate associations.</p>
<p>In bivariate analysis, we always start with a <strong>research question</strong>. Do Black and other ethnic minority citizens experience police stops more often than White citizens (i.e., <em>ethnicity</em> <span class="math inline">\(\rightarrow\)</span> <em>police stops</em>)? Are violent crimes more common in low-income countries than in high-income countries (<em>income level</em> <span class="math inline">\(\rightarrow\)</span> <em>violent crimes</em>)? Are people living in urban areas more likely to be victims of crime than those in rural areas (<em>urbanisation</em> <span class="math inline">\(\rightarrow\)</span> <em>crime victimisation</em>)? These criminologically relevant research questions require the analysis of two variables simultaneously.</p>
<p>To answer a research question, we formulate a research hypothesis (or sometimes several research hypotheses related to it). A research hypothesis is simply a proposed answer to our research question that we can test by carrying out some research. Research hypotheses can be directional and non-directional:</p>
<blockquote>
<p>“When the research hypothesis does not indicate a specific type of outcome, stating only that there is a relationship or a difference, we say that it is a <strong>non-directional hypothesis</strong>. However, in those cases where a researcher has a very clear idea of what to expect—based on prior research evidence and/or theory—the research hypothesis may be more precise. In this case, the researcher may specify the nature of the relationship that is expected. Such a research hypothesis is called a <strong>directional hypothesis</strong>. When a directional hypothesis is used, the researcher states at the outset that he or she is interested in a specific type of outcome -for example, that one group has more arrests than another. Suppose we are interested in comparing the arrest records of drug-involved offenders with those of offenders who do not use drugs. Our research hypothesis might be simply that the arrest records of drug-involved offenders and offenders who do not use drugs are different (a nondirectional hypothesis). But based on prior knowledge of criminal behaviour among drug-involved offenders, we might want to state a directional hypothesis - that drug-involved offenders have more serious arrest records than non-drug-involved offenders do. One problem with choosing the latter option is that if we state our research hypothesis as a directional hypothesis, we are stating that we are not interested in outcomes that fall in the opposite direction. In criminal justice research, we can often be surprised by what we learn in a study. Accordingly, researchers generally are cautious in defining a directional research hypothesis” (Weisburd and Britt, 2010: 120)</p>
</blockquote>
<p>When formulating a research hypothesis, it is common practice to also formulate a <em>null hypothesis</em>. We will return to this discussion in more detail in Chapter 9 when introducing statistical inference. For now, it suffices to say that science always takes a sceptical approach and tests hypotheses against empirical data. For example, consider the research question: do Black and other ethnic minority citizens experience police stops more often than White citizens? Based on prior research (e.g., <a href="https://www.nature.com/articles/s41562-020-01029-w">here</a> or <a href="https://www.cambridge.org/core/journals/american-political-science-review/article/administrative-records-mask-racially-biased-policing/66BC0F9998543868BB20F241796B79B8">here</a>), our research hypothesis could be that Black and other ethnic minority citizens are stopped by the police more frequently than White citizens. A sceptical approach, however, would begin with a null hypothesis: <em>there is no difference in the frequency of police stops experienced by Black and other minority citizens compared to White citizens</em>. We then <strong>test</strong> this null hypothesis against empirical data to draw conclusions about the association between ethnicity and the experience of police stops. More details on the rationale behind null hypotheses and the principles of hypothesis testing will be provided in Chapter 9!</p>
<p>From the research question and the research hypothesis (as well as the null hypothesis), we identify two variables, each with a distinct role. One variable represents the <em>explanandum</em>, the phenomenon we aim to explain—this is called the <strong>dependent variable</strong> (also referred to as the <em>outcome variable</em> or <em>response variable</em>). The other variable is the <em>explanans</em>, the phenomenon used to explain it—this is called the <strong>independent variable</strong> (also known as the <em>explanatory variable</em> or <em>predictor variable</em>). For example, in the question we explored earlier—<em>Do Black and other ethnic minority citizens experience police stops more often than White citizens?</em>— we are examining how the frequency of police stops varies depending on a person’s ethnicity. In this case, the frequency of police stops is the dependent variable, as it is the phenomenon we want to explain. Ethnicity is the independent variable, as it is the factor we believe influences the dependent variable. From now on, we will consistently identify dependent and independent variables based on research questions and hypotheses.</p>
<style>
details {
  margin-bottom: 1em; /* Adds space below each details block */
}
</style>
<p><strong>Your turn!</strong> In the research questions below, identify the dependent variable and the independent variable:</p>
<ul>
<li>Are violent crimes more common in low-income countries than in high-income countries?</li>
</ul>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<ul>
<li><strong>Unit of analysis</strong>: <em>countries</em><br />
</li>
<li><strong>Dependent variable</strong>: <em>frequency of violent crimes</em><br />
</li>
<li><strong>Independent variable</strong>: <em>income level</em></li>
</ul>
</details>
<ul>
<li>Are people living in urban areas more likely to be victims of crime than those in rural areas?</li>
</ul>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<ul>
<li><strong>Unit of analysis</strong>: <em>people / members of the public</em><br />
</li>
<li><strong>Dependent variable</strong>: <em>likelihood of crime victimisation</em><br />
</li>
<li><strong>Independent variable</strong>: <em>urbanisation, or residence area characteristics (e.g., urban vs. rural areas)</em></li>
</ul>
</details>
<ul>
<li>Do neighbourhoods with a heavier police presence experience less crime?</li>
</ul>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<ul>
<li><strong>Unit of analysis</strong>: <em>neighbourhoods</em><br />
</li>
<li><strong>Dependent variable</strong>: <em>frequency of crimes</em><br />
</li>
<li><strong>Independent variable</strong>: <em>police prevalence (e.g., heavily policed vs. lightly policed)</em></li>
</ul>
</details>
<ul>
<li>Does being on probation reduce the likelihood of reoffending compared to individuals not on probation?</li>
</ul>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<ul>
<li><strong>Unit of analysis</strong>: <em>individuals / previous offenders</em><br />
</li>
<li><strong>Dependent variable</strong>: <em>likelihood of reoffending</em><br />
</li>
<li><strong>Independent variable</strong>: <em>probation (e.g., being on probation vs. not on probation)</em></li>
</ul>
</details>
<ul>
<li>Does cannabis legalisation lead to higher self-reported levels of cannabis use?</li>
</ul>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<ul>
<li><strong>Unit of analysis</strong>: <em>countries / cities / states</em><br />
</li>
<li><strong>Dependent variable</strong>: <em>self-reported levels of cannabis use</em><br />
</li>
<li><strong>Independent variable</strong>: <em>cannabis legislation (e.g., legalised vs. prohibited)</em></li>
</ul>
</details>
</div>
<div id="dependent-variable-numerical-independent-variable-binary" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Dependent variable: numerical | Independent variable: binary<a href="regression-i-mean-differences.html#dependent-variable-numerical-independent-variable-binary" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Throughout the semester, we will explore how to analyse relationships between variables across various combinations. If you examine the research questions above, they share a key feature: all the dependent variables are numerical, and all the independent variables are binary. Numerical variables represent measurable or countable quantities where arithmetic operations like addition, subtraction, multiplication, and division are meaningful. Examples from the research questions include the frequency of police stops, frequency of violent crimes, likelihood of crime victimisation, frequency of crimes, likelihood of reoffending, and self-reported levels of cannabis use. These are all numerical variables because they have numerical values that can be counted or measured. Binary variables (also referred to as dichotomous or dummy variables), on the other hand, represent categorical data with two mutually exclusive and exhaustive categories. Binary variables include only two possible levels, such as <code>TRUE</code> or <code>FALSE</code>, yes or no, or two distinct groupings. Examples from the research questions include: ethnicity (e.g., White vs. Black and other ethnic minorities), countries’ income level (e.g., low-income vs. high-income), area characteristics (e.g., urban vs. rural areas), police prevalence in neighbourhoods (e.g., heavily policed vs. lightly policed), probation status (e.g., being on probation vs. not being on probation), and cannabis legislation (e.g., legalised vs. prohibited)</p>
<p>This is the first bivariate analysis we will study.</p>
<style>
div {
  margin-bottom: 1em; /* Adds space below each details block */
}
</style>
<div style="border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;">
<p><b>FIRST BIVARIATE ANALYSIS</b></p>
<p><b>Dependent variable:</b> <i>Numerical</i></br>
<b>Independent variable:</b> <i>Binary</i></p>
</div>
<p>Let’s elaborate with an example. Let’s start with the following research question: <em>are women more afraid of violent crime than men?</em> Previous research has consistently demonstrated a gender disparity in fear of crime, with women reporting higher levels of fear compared to men (e.g., <a href="https://www.tandfonline.com/doi/full/10.1080/07352166.2021.1923372?utm_source=chatgpt.com">here</a>, <a href="https://academic.oup.com/bjc/article-abstract/51/1/58/344723?redirectedFrom=fulltext&amp;login=false&amp;utm_source=chatgpt.com">here</a>, <a href="https://academic.oup.com/bjc/article-abstract/44/6/946/397351">here</a>). While the dynamics of crime victimisation risk differ between men and women, the fear-gender gap persists across various contexts.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>Based on previous research, our research hypothesis is that women are more afraid of violent crime than men. However, adopting a sceptical approach, our <em>null hypothesis</em> states that <em>there are no differences in fear of crime between men and women</em>. To test this, we must contrast this statement with empirical data. For this example, we will use data from the Crime Survey for England and Wales (2007–08), which provides a representative sample of the adult population living in England and Wales. This dataset includes information on respondents’ fear of crime, making it suitable for addressing our research question. Let’s begin by loading the dataset.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="regression-i-mean-differences.html#cb323-1" tabindex="-1"></a><span class="co"># load readr library and import the data using read_csv() function</span></span>
<span id="cb323-2"><a href="regression-i-mean-differences.html#cb323-2" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb323-3"><a href="regression-i-mean-differences.html#cb323-3" tabindex="-1"></a>csew_0708 <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/uom-resquant/modelling_book/refs/heads/master/datasets/BCS0708.csv&quot;</span>)</span></code></pre></div>
<p>The variables of interest in our analysis are <code>tcviolent</code> and <code>sex.</code> The variable <code>tcviolent</code> is an index of fear of violent crime, measured on a numerical scale where lower scores indicate less fear and higher scores indicate greater fear. To summarise this variable, we can use the <code>summary()</code> function. As shown below, the mean score is 0.05, with a minimum of -2.35 and a maximum of 3.81.</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="regression-i-mean-differences.html#cb324-1" tabindex="-1"></a><span class="fu">summary</span>(csew_0708<span class="sc">$</span>tcviolent)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##  -2.350  -0.672  -0.117   0.046   0.540   3.805    3242</code></pre>
<p>In this dataset, <code>sex</code> is a binary variable—unfortunately, the survey instrument did not measure gender identification and is limited to responses recorded as ‘male’ or ‘female’. We can use the <code>table()</code> and <code>prop.table()</code> functions to summarise this variable, which respectively provide counts and proportions of the number of observations in our data that take distinct values for a given variable. 6369 (55%) respondents were recorded as female, whereas 5307 (45%) were recorded as male.</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="regression-i-mean-differences.html#cb326-1" tabindex="-1"></a><span class="fu">table</span>(csew_0708<span class="sc">$</span>sex)</span></code></pre></div>
<pre><code>## 
## female   male 
##   6369   5307</code></pre>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="regression-i-mean-differences.html#cb328-1" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(csew_0708<span class="sc">$</span>sex))</span></code></pre></div>
<pre><code>## 
##    female      male 
## 0.5454779 0.4545221</code></pre>
</div>
<div id="calculating-mean-differences-in-r" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Calculating mean differences in <code>R</code><a href="regression-i-mean-differences.html#calculating-mean-differences-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now, how can we examine whether women are more afraid of violent crime than men? To address this research question, we need to evaluate the association between the variables <code>tcviolent</code> and <code>sex</code>. This process builds on concepts introduced in Chapter 3. In Chapter 3, we learned how to describe numerical variables using measures of central tendency (such as the mean and the median) and measures of dispersion (such as the standard deviation and the range). Among these, the mean is particularly effective for summarising symmetric and normally distributed data.</p>
<p>Given this, one straightforward strategy to assess whether women are more afraid of violent crime than men is to calculate the mean level of fear of violent crime <em>only among women</em> and compare it to the mean level of fear <em>only among men</em>. Adopting a sceptical approach—recalling the null hypothesis, which states that <em>there are no differences in fear of crime between men and women</em>—we would expect these two means to be roughly equal. If the means differ, this would provide <em>evidence against the null hypothesis</em>, suggesting that fear of violent crime varies between men and women and that the two variables (<code>tcviolent</code> and <code>sex</code>) are associated. In this context, the <strong>mean difference serves as the measure of association between a numerical dependent variable (</strong><code>tcviolent</code><strong>) and a binary independent variable (</strong><code>sex</code><strong>)</strong>.</p>
<p>To calculate the mean of a numerical variable for specific subgroups, we can use the <code>filter()</code> function from the <code>dplyr</code> package. The <code>filter()</code> function allows us to subset the data based on specified conditions. For example, we can use the <code>filter()</code> function to calculate the mean of fear of violent crime for women and the mean of fear of violent crime for men. Note that when using <code>filter()</code>, you need to use a double equals sign (<code>==</code>) to specify equality.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="regression-i-mean-differences.html#cb330-1" tabindex="-1"></a><span class="co"># Install the &#39;dplyr&#39; package if you haven&#39;t already</span></span>
<span id="cb330-2"><a href="regression-i-mean-differences.html#cb330-2" tabindex="-1"></a><span class="co"># install.packages(&quot;dplyr&quot;)</span></span>
<span id="cb330-3"><a href="regression-i-mean-differences.html#cb330-3" tabindex="-1"></a></span>
<span id="cb330-4"><a href="regression-i-mean-differences.html#cb330-4" tabindex="-1"></a><span class="co"># Load the dplyr package</span></span>
<span id="cb330-5"><a href="regression-i-mean-differences.html#cb330-5" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb330-6"><a href="regression-i-mean-differences.html#cb330-6" tabindex="-1"></a></span>
<span id="cb330-7"><a href="regression-i-mean-differences.html#cb330-7" tabindex="-1"></a><span class="co"># Subset the data for female respondents</span></span>
<span id="cb330-8"><a href="regression-i-mean-differences.html#cb330-8" tabindex="-1"></a>csew_0708_women <span class="ot">&lt;-</span> <span class="fu">filter</span>(csew_0708, sex <span class="sc">==</span> <span class="st">&quot;female&quot;</span>)</span>
<span id="cb330-9"><a href="regression-i-mean-differences.html#cb330-9" tabindex="-1"></a></span>
<span id="cb330-10"><a href="regression-i-mean-differences.html#cb330-10" tabindex="-1"></a><span class="co"># Check the number of rows in the filtered dataset</span></span>
<span id="cb330-11"><a href="regression-i-mean-differences.html#cb330-11" tabindex="-1"></a><span class="fu">nrow</span>(csew_0708_women)</span></code></pre></div>
<pre><code>## [1] 6369</code></pre>
<p>As expected, the <code>csew_0708_women</code> dataset contains 6369 rows. This is the number of female respondents we had obtained before.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="regression-i-mean-differences.html#cb332-1" tabindex="-1"></a><span class="co"># Subset the data for male respondents</span></span>
<span id="cb332-2"><a href="regression-i-mean-differences.html#cb332-2" tabindex="-1"></a>csew_0708_men <span class="ot">&lt;-</span> <span class="fu">filter</span>(csew_0708, sex <span class="sc">==</span> <span class="st">&quot;male&quot;</span>)</span>
<span id="cb332-3"><a href="regression-i-mean-differences.html#cb332-3" tabindex="-1"></a></span>
<span id="cb332-4"><a href="regression-i-mean-differences.html#cb332-4" tabindex="-1"></a><span class="co"># Check the number of rows in the filtered dataset</span></span>
<span id="cb332-5"><a href="regression-i-mean-differences.html#cb332-5" tabindex="-1"></a><span class="fu">nrow</span>(csew_0708_men)</span></code></pre></div>
<pre><code>## [1] 5307</code></pre>
<p>Similarly, the <code>csew_0708_men</code> dataset contains 5307 rows, corresponding to the number of male respondents in the dataset.</p>
<p>Now, let’s calculate the mean level of fear of violent crime (<code>tcviolent</code>) for each subgroup:</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="regression-i-mean-differences.html#cb334-1" tabindex="-1"></a><span class="co"># Calculate the mean of fear of violent crime for women</span></span>
<span id="cb334-2"><a href="regression-i-mean-differences.html#cb334-2" tabindex="-1"></a>mean_fear_women <span class="ot">&lt;-</span> <span class="fu">mean</span>(csew_0708_women<span class="sc">$</span>tcviolent, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb334-3"><a href="regression-i-mean-differences.html#cb334-3" tabindex="-1"></a></span>
<span id="cb334-4"><a href="regression-i-mean-differences.html#cb334-4" tabindex="-1"></a><span class="co"># Calculate the mean of fear of violent crime for men</span></span>
<span id="cb334-5"><a href="regression-i-mean-differences.html#cb334-5" tabindex="-1"></a>mean_fear_men <span class="ot">&lt;-</span> <span class="fu">mean</span>(csew_0708_men<span class="sc">$</span>tcviolent, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb334-6"><a href="regression-i-mean-differences.html#cb334-6" tabindex="-1"></a></span>
<span id="cb334-7"><a href="regression-i-mean-differences.html#cb334-7" tabindex="-1"></a><span class="co"># Display the mean of fear of violent crime for women</span></span>
<span id="cb334-8"><a href="regression-i-mean-differences.html#cb334-8" tabindex="-1"></a>mean_fear_women</span></code></pre></div>
<pre><code>## [1] 0.3281656</code></pre>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="regression-i-mean-differences.html#cb336-1" tabindex="-1"></a><span class="co"># Display the mean of fear of violent crime for men</span></span>
<span id="cb336-2"><a href="regression-i-mean-differences.html#cb336-2" tabindex="-1"></a>mean_fear_men</span></code></pre></div>
<pre><code>## [1] -0.2738322</code></pre>
<p>The mean level of fear of violent crime among women is 0.33, while among men, it is -0.27. As anticipated, women report higher levels of fear of violent crime than men (since 0.33 <span class="math inline">\(&gt;\)</span> -0.27), providing evidence that gender differences in fear of crime exist.</p>
<p>To refine our analysis, we can calculate the mean difference between the fear of violent crime scores for men and women. The mean difference is simply the result of subtracting one group’s mean from the other.</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="regression-i-mean-differences.html#cb338-1" tabindex="-1"></a><span class="co"># Calculate the mean difference</span></span>
<span id="cb338-2"><a href="regression-i-mean-differences.html#cb338-2" tabindex="-1"></a>mean_difference <span class="ot">&lt;-</span> mean_fear_men <span class="sc">-</span> mean_fear_women</span>
<span id="cb338-3"><a href="regression-i-mean-differences.html#cb338-3" tabindex="-1"></a></span>
<span id="cb338-4"><a href="regression-i-mean-differences.html#cb338-4" tabindex="-1"></a><span class="co"># Display the mean difference</span></span>
<span id="cb338-5"><a href="regression-i-mean-differences.html#cb338-5" tabindex="-1"></a>mean_difference</span></code></pre></div>
<pre><code>## [1] -0.6019978</code></pre>
<p>The mean difference is -0.6. This indicates that the average score of fear of violent crime among male respondents is 0.6 lower than the average score among female respondents.</p>
<details>
<summary>
<b>Note:</b> The order of subtraction matters in interpreting the result, even though it does not change the numerical value.
</summary>
<p>Subtracting the mean for women from the mean for men highlights that men have lower fear scores while reversing the subtraction would emphasize that women have higher fear scores. It is crucial to align the direction of subtraction with the focus of the research question or the narrative you wish to convey. For example:</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="regression-i-mean-differences.html#cb340-1" tabindex="-1"></a><span class="co"># Calculate the mean difference using the alternative order </span></span>
<span id="cb340-2"><a href="regression-i-mean-differences.html#cb340-2" tabindex="-1"></a>mean_difference_alternative <span class="ot">&lt;-</span> mean_fear_women <span class="sc">-</span> mean_fear_men</span>
<span id="cb340-3"><a href="regression-i-mean-differences.html#cb340-3" tabindex="-1"></a></span>
<span id="cb340-4"><a href="regression-i-mean-differences.html#cb340-4" tabindex="-1"></a><span class="co"># Display the mean difference</span></span>
<span id="cb340-5"><a href="regression-i-mean-differences.html#cb340-5" tabindex="-1"></a>mean_difference_alternative</span></code></pre></div>
<pre><code>## [1] 0.6019978</code></pre>
<p>In this case, the mean difference is 0.6. This indicates that the average score of fear of crime among female respondents is 0.6 higher than the average score among male respondents.</p>
</details>
<p>If the null hypothesis were true (i.e., adopting a sceptical approach), we would expect the means for both groups to be approximately the same, resulting in a mean difference close to zero. A mean difference of -0.6 suggests that women tend to report higher levels of fear of violent crime than men in the Crime Survey for England and Wales, providing some evidence that allows us to address our research question.</p>
</div>
<div id="visual-exploration" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Visual exploration<a href="regression-i-mean-differences.html#visual-exploration" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One simple strategy to depict the association between a numerical dependent variable and a binary independent variable (i.e., the mean difference) involves using data visualisation techniques. We already covered this in Chapter 3! For example, when we want to visualise the distribution of a numerical variable, we can produce a histogram, a density plot, or a boxplot. If we want to graphically represent the distribution of a numerical variable across two groups, we can produce a grouped histogram, a grouped density plot, or a grouped boxplot. This allows us to assess the association between a numerical dependent variable and a binary independent variable by examining their mean difference.</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="regression-i-mean-differences.html#cb342-1" tabindex="-1"></a><span class="co"># load the ggplot2 package</span></span>
<span id="cb342-2"><a href="regression-i-mean-differences.html#cb342-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb342-3"><a href="regression-i-mean-differences.html#cb342-3" tabindex="-1"></a></span>
<span id="cb342-4"><a href="regression-i-mean-differences.html#cb342-4" tabindex="-1"></a><span class="co"># produce a grouped density plot</span></span>
<span id="cb342-5"><a href="regression-i-mean-differences.html#cb342-5" tabindex="-1"></a><span class="fu">ggplot</span>(csew_0708, <span class="fu">aes</span>(<span class="at">x =</span> tcviolent, <span class="at">fill =</span> sex)) <span class="sc">+</span> </span>
<span id="cb342-6"><a href="regression-i-mean-differences.html#cb342-6" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> .<span class="dv">3</span>)</span></code></pre></div>
<p><img src="05_regresion_I_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>This grouped density plot shows that the distribution of <em>fear of violent crime</em> (<code>tcviolent</code>) scores among female respondents is slightly shifted to the right compared to the distribution among male respondents. This suggests an association between gender and fear of violent crime—as we already knew—as women in this sample have a higher average score than men. The same pattern can be visualised with a grouped boxplot.</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="regression-i-mean-differences.html#cb343-1" tabindex="-1"></a><span class="co"># produce a grouped boxplot</span></span>
<span id="cb343-2"><a href="regression-i-mean-differences.html#cb343-2" tabindex="-1"></a><span class="fu">ggplot</span>(csew_0708, <span class="fu">aes</span>(<span class="at">x =</span> sex, <span class="at">y =</span> tcviolent)) <span class="sc">+</span> </span>
<span id="cb343-3"><a href="regression-i-mean-differences.html#cb343-3" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>()</span></code></pre></div>
<p><img src="05_regresion_I_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="using-linear-regression-to-calculate-mean-differences" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Using linear regression to calculate mean differences<a href="regression-i-mean-differences.html#using-linear-regression-to-calculate-mean-differences" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Calculating mean differences in <code>R</code> is straightforward, as demonstrated above. We first filter the dataset by the groups of interest, compute the mean of the dependent variable for each group, and then calculate the difference between the two group-specific means. While this step-by-step approach is effective, it can become time-consuming when repeated for multiple analyses. Fortunately, <code>R</code> offers a more efficient alternative: the <code>lm()</code> function.</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="regression-i-mean-differences.html#cb344-1" tabindex="-1"></a><span class="fu">lm</span>(dependent_variable <span class="sc">~</span> independent variable, <span class="at">data =</span> dataset)</span></code></pre></div>
<p>The <code>lm()</code> function, short for <em>linear mode</em>l, streamlines the process by calculating the mean difference directly. The function’s structure is simple:</p>
<ul>
<li>Specify the dependent variable first.</li>
<li>Follow it with a <em>tilde</em> (<span class="math inline">\(\sim\)</span>).</li>
<li>Then, provide the independent variable and the dataset.</li>
</ul>
<p>When the dependent variable is numerical and the independent variable is binary, the <code>lm()</code> function automatically calculates the mean difference. It saves time by performing all the necessary steps in one go. You can use it directly or save the output to an object for later use. For our example, the code would look like this:</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="regression-i-mean-differences.html#cb345-1" tabindex="-1"></a><span class="co"># Linear model calculating the difference in fear of crime by sex</span></span>
<span id="cb345-2"><a href="regression-i-mean-differences.html#cb345-2" tabindex="-1"></a>mean_difference_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(tcviolent <span class="sc">~</span> sex, <span class="at">data =</span> csew_0708)</span></code></pre></div>
<p>In this case:</p>
<ul>
<li><code>tcviolent</code> is the dependent variable (a numerical variable).</li>
<li><code>sex</code> is the independent variable (a binary variable).</li>
<li><code>csew_0708</code> is the dataset being analysed.</li>
<li><code>mean_difference_lm</code> is the name we assign to the object storing the model’s results.</li>
</ul>
<p>This single line of code computes the mean difference in fear of violent crime between men and women based on the dataset <code>csew_0708</code>, offering a more streamlined approach to the analysis. Now, let’s examine the output.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="regression-i-mean-differences.html#cb346-1" tabindex="-1"></a><span class="co"># Display the results of the linear model</span></span>
<span id="cb346-2"><a href="regression-i-mean-differences.html#cb346-2" tabindex="-1"></a>mean_difference_lm</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = tcviolent ~ sex, data = csew_0708)
## 
## Coefficients:
## (Intercept)      sexmale  
##      0.3282      -0.6020</code></pre>
<p>The output has two parts:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Call:</strong> This section restates the formula you provided to the function, confirming that <code>tcviolent</code> is the dependent variable, <code>sex</code> is the independent variable, and <code>csew_0708</code> is the dataset.</p></li>
<li><p><strong>Coefficients:</strong> This section provides the results we’re most interested in, showing two estimates:</p>
<ul>
<li><code>(Intercept):</code> 0.3282</li>
<li><code>sexmale:</code> -0.6020</li>
</ul></li>
</ol>
<p>If you recall from above, when we manually calculated everything, these numbers should look familiar! The average score of fear of violent crime among women (remember, we created the <code>mean_fear_women</code> object) was 0.3282—exactly what is reported as the <em>Intercept</em> in this output. And the mean difference (remember, we created the <code>mean_difference</code> object) was -0.602—exactly what is reported as the <code>sexmale</code> coefficient! This implies that male respondents have a fear score that is 0.3282 points lower than female respondents on average.</p>
<details>
<summary>
<b>Note on how to figure out which comparisons the model is making:</b>
</summary>
<p>As we discussed above, there are two possible comparisons. They are numerically equivalent (i.e., only the sign differs), but the interpretation changes. We can calculate <code>mean_fear_men - mean_fear_women</code>, which gives a mean difference of -0.602. Alternatively, we can calculate <code>mean_fear_women - mean_fear_men</code>, as we did when we created the <code>mean_difference_alternative</code> object, which gives a mean difference of 0.602. While these values are numerically the same, their interpretation focuses on different groups.</p>
<div id="how-to-determine-which-comparison-lm-is-performing" class="section level4 unnumbered hasAnchor">
<h4>How to determine which comparison <code>lm()</code> is performing<a href="regression-i-mean-differences.html#how-to-determine-which-comparison-lm-is-performing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <code>lm()</code> function selects one category to be represented by the <em>Intercept</em>—this is known as the <em>reference category</em>. The reference category is the group being compared against, i.e., the right-hand side of the subtraction equation. The <code>lm()</code> function then calculates the difference between the other category and the reference category. This is visible in the output. For example, in the output above, the coefficient is labelled <code>sexmale</code>. This implies that <em>female</em> is the reference category, and the comparison being made is <code>mean_fear_men - mean_fear_women</code>. The coefficient <code>sexmale:</code> -0.602 therefore indicates that male respondents, on average, have a fear score -0.602 points lower than female respondents.</p>
<p><strong>How R determines the reference category</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Character Variables:</strong> If the independent variable is a <code>character</code> variable, <code>lm()</code> selects the first group alphabetically as the reference category. In this example, <em>female</em> comes before <em>male</em>, so <em>female</em> is set as the reference category.</li>
<li><strong>Factor Variables:</strong> If the independent variable is a <code>factor</code>, you can manually set the reference category.</li>
<li><strong>Logical Variables:</strong> If the independent variable is <code>logical</code> (i.e., <code>TRUE</code> or <code>FALSE</code>), <code>FALSE</code> is automatically set as the reference category.</li>
</ol>
<p><strong>Changing the reference category</strong>. If we wanted to treat <em>male</em> as the reference category, we could do one of the following:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="regression-i-mean-differences.html#cb348-1" tabindex="-1"></a><span class="co"># Create a logical variable that is TRUE if the respondent is female </span></span>
<span id="cb348-2"><a href="regression-i-mean-differences.html#cb348-2" tabindex="-1"></a><span class="co"># and FALSE if the respondent is male</span></span>
<span id="cb348-3"><a href="regression-i-mean-differences.html#cb348-3" tabindex="-1"></a>csew_0708 <span class="ot">&lt;-</span> <span class="fu">mutate</span>(csew_0708, <span class="at">female_logical =</span> sex <span class="sc">==</span> <span class="st">&quot;female&quot;</span>)</span>
<span id="cb348-4"><a href="regression-i-mean-differences.html#cb348-4" tabindex="-1"></a></span>
<span id="cb348-5"><a href="regression-i-mean-differences.html#cb348-5" tabindex="-1"></a><span class="co"># Create a factor variable with &#39;male&#39; as the reference category</span></span>
<span id="cb348-6"><a href="regression-i-mean-differences.html#cb348-6" tabindex="-1"></a>csew_0708 <span class="ot">&lt;-</span> <span class="fu">mutate</span>(csew_0708, <span class="at">female_factor =</span> <span class="fu">factor</span>(sex, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)))</span></code></pre></div>
<p>We can then estimate new regression models using the female_logical and female_factor variables:</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="regression-i-mean-differences.html#cb349-1" tabindex="-1"></a><span class="co"># Estimate a linear regression using &#39;female_logical&#39; as the independent variable</span></span>
<span id="cb349-2"><a href="regression-i-mean-differences.html#cb349-2" tabindex="-1"></a><span class="fu">lm</span>(tcviolent <span class="sc">~</span> female_logical, <span class="at">data =</span> csew_0708)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = tcviolent ~ female_logical, data = csew_0708)
## 
## Coefficients:
##        (Intercept)  female_logicalTRUE  
##            -0.2738              0.6020</code></pre>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="regression-i-mean-differences.html#cb351-1" tabindex="-1"></a><span class="co"># Estimate a linear regression using &#39;female_factor&#39; as the independent variable</span></span>
<span id="cb351-2"><a href="regression-i-mean-differences.html#cb351-2" tabindex="-1"></a><span class="fu">lm</span>(tcviolent <span class="sc">~</span> female_factor, <span class="at">data =</span> csew_0708)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = tcviolent ~ female_factor, data = csew_0708)
## 
## Coefficients:
##         (Intercept)  female_factorfemale  
##             -0.2738               0.6020</code></pre>
<p>For both models, the outputs are identical. The <em>Intercept</em> now reflects the mean of fear of violent crime among male respondents (-0.27), as <em>male</em> is the reference category. The coefficient is also identical to the value stored in the <code>mean_difference_alternative</code> object (0.6). This coefficient is numerically equivalent to the previously estimated <code>sexmale</code> coefficient (-0.6), but the sign changes. With <em>male</em> as the reference group, the output reflects that female respondents have a fear score 0.6 points higher than male respondents on average.</p>
</details>
</div>
<div id="linear-regression" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Linear Regression<a href="regression-i-mean-differences.html#linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the previous section, we used the <code>lm()</code> function to estimate mean differences and learned that <code>lm</code> stands for <em>linear model</em>. This function provides a way to estimate relationships using a statistical model, specifically the most basic and widely used model: <strong>linear regression</strong>. At its core, linear regression characterises the relationship between a dependent variable and one (or more) independent variable(s) using a <em>linear model</em>:</p>
<p><span class="math display">\[
Y = \underbrace{\alpha}_{\text{Intercept}} + \underbrace{\beta \cdot}_{\text{Slope}} \! X + \!\!\!\!\! \underbrace{\epsilon}_{\text{Error Term}}
\]</span></p>
<p>In this equation:</p>
<ul>
<li><span class="math inline">\(Y\)</span> is the dependent variable.</li>
<li><span class="math inline">\(X\)</span> is the independent variable.</li>
</ul>
<p>By convention, the dependent variable (<span class="math inline">\(Y\)</span>) is always displayed on the left-hand side of the equation, while the independent variable (<span class="math inline">\(X\)</span>) is on the right-hand side. For example, in the context of our dataset, <span class="math inline">\(Y\)</span> might represent scores of fear of violent crime, and <span class="math inline">\(X\)</span> could represent sex.</p>
<p>It is also standard practice to use Latin letters (<span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>) for observed variables in our dataset, whereas Greek letters (<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\epsilon\)</span>) represent unknown parameters that need to be estimated.</p>
<ul>
<li>The <strong>intercept</strong> (<span class="math inline">\(\alpha\)</span>) represents the average value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X = 0\)</span>.<br />
</li>
<li>The <strong>slope</strong> (<span class="math inline">\(\beta\)</span>) measures the average increase in <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> increases by one unit.<br />
</li>
<li>Together, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are called <em>regression coefficients</em>. These coefficients are not directly observed in the data and must be estimated.</li>
</ul>
<p>Finally, the <strong>error term</strong> (<span class="math inline">\(\epsilon\)</span>) accounts for the variability in <span class="math inline">\(Y\)</span> that is not explained by <span class="math inline">\(X\)</span>. We will elaborate on this concept in the sections that follow.</p>
<p>Linear regression is a widely used statistical model in the social sciences. Over the coming weeks, we will extend several aspects of this model. Regression models serve two main purposes: prediction and theory testing. These models allow us to specify research questions and translate them into statistical representations, assuming the model approximates the <em>data-generating process</em>.</p>
<p>In reality, we do not know the true data-generating process, and our statistical model may be incomplete. For example, factors beyond gender—such as prior victimisation (of oneself or family/friends), local crime rates, or individual personality traits—may also influence people’s fear of violent crime. While these factors are not included in our current model, that’s acceptable. As the saying goes, “all models are wrong, but some are useful.” Our primary goal is not to explain all variations in the dependent variable (e.g., fear of crime) but to address our research question. In this case, we aim to determine whether women are more afraid of violent crime than men by estimating the difference in average fear scores between the two groups.</p>
<p>Over the next few weeks, we will expand our understanding of linear regression models in various ways:</p>
<ul>
<li>Independent variables can also be numerical (Chapter 6).</li>
<li>Linear regression models have several assumptions that need to be satisfied (Chapter 6).</li>
<li>Independent variables can be categorical with more than two groups (Chapter 7).<br />
</li>
<li>Multiple independent variables can be included simultaneously (Chapter 7).</li>
</ul>
<p>For now, we are focusing on a basic scenario: a numerical dependent variable and a binary independent variable. In this case, the estimated slope coefficient corresponds to the <em>difference-in-means estimator</em>.</p>
</div>
<div id="linear-regression-as-a-difference-in-means-estimator" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Linear Regression as a Difference-in-Means Estimator<a href="regression-i-mean-differences.html#linear-regression-as-a-difference-in-means-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s apply this to our example. The regression equation can be written as:</p>
<p><span class="math display">\[
\widehat{tcviolent} = \widehat{\alpha} + \widehat{\beta} \cdot sex
\]</span></p>
<p>Here, <code>tcviolent</code> (a variable reflecting scores of fear of violent crime) is the dependent variable, and <code>sex</code> is the independent variable. We aim to estimate the parameters <span class="math inline">\(\alpha\)</span> (the intercept) and <span class="math inline">\(\beta\)</span> (the slope), which help us address the research question. Linear regression employs <em>ordinary least squares</em> (OLS)—a method we will study in more detail next week—to estimate <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. The <code>lm()</code> function, introduced earlier, performs this estimation. Let’s revisit the regression output:</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="regression-i-mean-differences.html#cb353-1" tabindex="-1"></a><span class="co"># Display the results of the linear model</span></span>
<span id="cb353-2"><a href="regression-i-mean-differences.html#cb353-2" tabindex="-1"></a>mean_difference_lm</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = tcviolent ~ sex, data = csew_0708)
## 
## Coefficients:
## (Intercept)      sexmale  
##      0.3282      -0.6020</code></pre>
<p>From the output:</p>
<ul>
<li>The intercept is 0.3282, meaning <span class="math inline">\(\widehat{\alpha} =\)</span> 0.3282.</li>
<li>The slope is -0.602, meaning <span class="math inline">\(\widehat{\beta} =\)</span> -0.602.</li>
</ul>
<p>Thus, we can rewrite the regression equation as:</p>
<p><span class="math display">\[
\widehat{tcviolent} = 0.3282 - 0.6020 \cdot sex
\]</span></p>
<p>Now, how does this equation make sense in practice? As noted earlier, <code>tcviolent</code> is a numerical variable, ranging from -2.35 to 3.81. Since it is numerical, arithmetic operations are meaningful, making its inclusion in a regression equation straightforward. After all, the goal is to estimate expected scores of <code>tcviolent</code> under specific conditions.</p>
<p>However, <code>sex</code> is not a numerical variable; it is a binary variable with two possible values: <em>female</em> and <em>male.</em> How can we incorporate such a variable into an equation?</p>
<p>The trick lies in treating binary variables as a special type of numerical variable. Binary variables can only take two distinct values (e.g., <code>TRUE</code> or <code>FALSE</code>, yes or no, black or white). By assigning meaningful numeric values, such as <code>1</code> or <code>0</code>, to the categories, they can be seamlessly included in equations. In this case, the variable sex is coded as follows:</p>
<ul>
<li><span class="math inline">\(sex = 0\)</span> if <code>sex</code> is <em>female</em></li>
<li><span class="math inline">\(sex = 1\)</span> if <code>sex</code> is <em>male</em></li>
</ul>
<p>Conventionally, the group assigned a value of <code>0</code> is the <em>reference group</em> (or sometimes referred to as the <em>control group</em>), while the group assigned a value of <em>1</em> is called the <em>comparison group</em> (or sometimes the <em>treatment group</em>).</p>
<p>By applying this coding to the linear regression model, we can interpret the results as follows:</p>
<ul>
<li><p>For <span class="math inline">\(sex=0\)</span> (i.e., females):</p>
<p><span class="math display">\[
\widehat{tcviolent} = 0.3282 - 0.6020 \cdot 0 \\
\widehat{tcviolent} = 0.3282
\]</span></p></li>
<li><p>For <span class="math inline">\(sex = 1\)</span> (i.e., males):</p>
<p><span class="math display">\[
\widehat{tcviolent} = 0.3282 - 0.6020 \cdot 1 \\
\widehat{tcviolent} = -0.2738
\]</span></p></li>
</ul>
<p>These equations illustrate how linear regression estimates mean differences. The intercept (<span class="math inline">\(\alpha\)</span>) represents the mean outcome for the reference group (e.g., the average fear of violent crime score among females), while the slope coefficient (<span class="math inline">\(\beta\)</span>) reflects the difference in means between the two groups.</p>
<p>Thus, in this example:</p>
<ul>
<li>The mean fear of violent crime score for females is <span class="math inline">\(\alpha = 0.3282\)</span>.</li>
<li>The mean fear of violent crime score for males is <span class="math inline">\(\alpha + \beta = 0.3282 - 0.6020 = -0.2738\)</span>.</li>
<li>The slope coefficient (<span class="math inline">\(\beta = -0.6020\)</span>) quantifies the difference in means between the two groups.</li>
</ul>
<p>Linear regression provides a straightforward way to quantify and interpret these differences.</p>
<details>
<summary>
<b>Why do we include “hats” in the parameters (e.g., <span class="math inline">\(\widehat{Y}\)</span>, <span class="math inline">\(\widehat{\alpha}\)</span>, <span class="math inline">\(\widehat{\beta}\)</span>)?</b>
</summary>
<p>The linear regression model is expressed as:</p>
<p><span class="math display">\[
Y = \alpha + \beta \cdot X + \epsilon
\]</span></p>
<p>Here, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are <em>unknown</em> parameters that need to be estimated. We can attempt to estimate (e.g., calculate) them. A common method for estimating these linear regression coefficients is the method of <em>least squares</em>. However, because we don’t know whether our estimates of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> perfectly match the unknown parameters, we need to distinguish the estimates from the unknown values. That’s where the “hats” come in.</p>
<ul>
<li><span class="math inline">\(\widehat{\alpha}\)</span> and <span class="math inline">\(\widehat{\beta}\)</span> represent the estimates (think <em>guesstimates</em>!) of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, respectively.</li>
<li>The “hat” indicates that these are estimated values, not the true parameters.</li>
</ul>
<p>We usually expect our estimator to do a good job of estimating parameters. To the extent that <span class="math inline">\(\widehat{\alpha} = \alpha\)</span> and <span class="math inline">\(\widehat{\beta} = \beta\)</span> can be proved, then we would have an <em>unbiased estimator</em>. (but don’t worry, that’s not something we need to worry about! That’s a job for theoretical statisticians).</p>
<p>Once we have estimated values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we can use them to <em>predict</em> the value of the dependent variable <span class="math inline">\(Y\)</span> for a given value of the independent variable <span class="math inline">\(X\)</span> (e.g., predict the value of fear of violent crime given respondents’ sex). This <em>predicted value</em> (or <em>fitted value</em>) of <em>Y</em> is also an estimated value, therefore, we denote it as <span class="math inline">\(\widehat{Y}\)</span>. As such, we can write the regression function:</p>
<p><span class="math display">\[
\widehat{Y} = \widehat{\alpha} + \widehat{\beta} \cdot x
\]</span></p>
<p>In this equation, we did not include <span class="math inline">\(\epsilon\)</span>. In most cases, the predicted value <span class="math inline">\(\widehat{Y}\)</span> is not equal to the observed value <span class="math inline">\(Y\)</span>. For instance, while <span class="math inline">\(\widehat{Y}=0.3282\)</span> for <span class="math inline">\(X=0\)</span> (i.e., the average score of fear of violent crime among female respondents is <span class="math inline">\(0.3282\)</span>), most female respondents probably have an observed score of fear of violent crime that is not exactly <span class="math inline">\(0.3282\)</span>. Similarly, while <span class="math inline">\(\widehat{Y}=-0.2738\)</span> for <span class="math inline">\(X=1\)</span> (i.e., the average score of fear of violent crime among male respondents is <span class="math inline">\(-0.2738\)</span>), most male respondents probably have an observed score of fear of violent crime that is not exactly <span class="math inline">\(-0.2738\)</span>.</p>
<p>The difference between the observed value <span class="math inline">\(Y\)</span> and its predicted value <span class="math inline">\(\widehat{Y}\)</span> (e.g., the difference between each individual score of fear of violent crime and the estimates above) is called the <em>residual</em> and is given by:</p>
<p><span class="math display">\[
\widehat{\epsilon} = Y - \widehat{Y}.
\]</span></p>
<p>The residual (<span class="math inline">\(\widehat{\epsilon}\)</span>) is essentially the “error” in prediction. It represents the part of <span class="math inline">\(Y\)</span> that is not explained by <span class="math inline">\(X\)</span> using the regression model. The residual <span class="math inline">\(\widehat{\epsilon}\)</span> is also the error term <span class="math inline">\(\epsilon\)</span> with a hat, as it represents an estimate of the error term. When we write the linear model focused on <span class="math inline">\(Y\)</span>, we have unknown parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> as well as an error term accounting for variation in <span class="math inline">\(Y\)</span> not explained by <span class="math inline">\(X\)</span>. When we write the linear model focused on <span class="math inline">\(\widehat{Y}\)</span>, we have parameter estimates <span class="math inline">\(\widehat{\alpha}\)</span> and <span class="math inline">\(\widehat{\beta}\)</span> and no error term.</p>
<p>The distinction between the error term (<span class="math inline">\(\epsilon\)</span>) and the residual (<span class="math inline">\(\widehat{\epsilon}\)</span>), as well as the role of <span class="math inline">\(\widehat{Y}\)</span> versus <span class="math inline">\(Y\)</span>, will become clearer as we explore these concepts further next week!</p>
</details>
</div>
</div>
<div id="effect-size" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Effect size<a href="regression-i-mean-differences.html#effect-size" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we learned that when we have a numerical dependent variable and a binary independent variable, we can assess their association by calculating the mean difference. Any difference between the mean scores of the dependent variable in the reference group and the mean scores of the dependent variable in the comparison group indicates that both variables are associated. In our case, because the average score of fear of violent crime among male respondents is -0.27, and among female respondents it is 0.33, the mean difference of -0.6 represents the association between gender and fear of violent crime.</p>
<p>Is this enough, though? Does a mean difference of -0.6 imply a strong association? How large a difference would we need to observe to argue that there is a substantive difference? Let’s say, <em>hypothetically</em>, that the mean score of fear of violent crime among men was 0.32, and among women it was 0.33. In this hypothetical case, the mean difference would be <span class="math inline">\(0.01\)</span>. Would this mean difference be enough for us to conclude that there is an association? Technically, given that the mean difference is not <span class="math inline">\(0\)</span>, an association exists… but how strong is it? How can we assess the actual strength of an association?</p>
<p>The first step is looking at the scaling of the dependent variable. In our case, fear of violent crime (<code>tcviolent</code>) was measured using an artificial metric. It ranges from -2.35 to 3.81, with a range of 6.16 points. In this context, we can subjectively assess whether our estimated mean difference of -0.6 is weak or strong. In other words, considering a scale ranging from -2.35 to 3.81, female respondents have a mean score that is 0.6 higher than male respondents.</p>
<p>If that subjective assessment is not enough to have an intuitive understanding of the magnitude of the observed association, we can always look at a <strong>standardised measure of the effect size</strong>. You will find a number of standardised measures of effect size. They aim to give you a sense of how large these differences are by using a standardised metric. We are just going to use one of them, Cohen’s d, for this scenario. We can obtain this measure with the <code>cohen.d()</code> function from the <code>effsize</code> package, which you will have to install.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="regression-i-mean-differences.html#cb355-1" tabindex="-1"></a><span class="co"># install the &#39;effsize&#39; package. Remember: you only have to do this once.</span></span>
<span id="cb355-2"><a href="regression-i-mean-differences.html#cb355-2" tabindex="-1"></a><span class="co"># install.packages(&quot;effsize&quot;)</span></span>
<span id="cb355-3"><a href="regression-i-mean-differences.html#cb355-3" tabindex="-1"></a></span>
<span id="cb355-4"><a href="regression-i-mean-differences.html#cb355-4" tabindex="-1"></a><span class="co"># load the &#39;effsize&#39; package. You have to do this every time.</span></span>
<span id="cb355-5"><a href="regression-i-mean-differences.html#cb355-5" tabindex="-1"></a><span class="fu">library</span>(effsize)</span>
<span id="cb355-6"><a href="regression-i-mean-differences.html#cb355-6" tabindex="-1"></a></span>
<span id="cb355-7"><a href="regression-i-mean-differences.html#cb355-7" tabindex="-1"></a><span class="co"># compute the Cohen&#39;s d effect size</span></span>
<span id="cb355-8"><a href="regression-i-mean-differences.html#cb355-8" tabindex="-1"></a><span class="fu">cohen.d</span>(csew_0708<span class="sc">$</span>tcviolent <span class="sc">~</span> csew_0708<span class="sc">$</span>sex)</span></code></pre></div>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.6281126 (medium)
## 95 percent confidence interval:
##     lower     upper 
## 0.5843047 0.6719205</code></pre>
<p>The output suggests that the Cohen’s d estimate is a medium effect size. Cohen proposed a set of rules of thumb to interpret the d statistic: an effect size (in absolute value) of 0.2 to 0.3 might be a “small” effect, around 0.5 a “medium” effect and 0.8 to infinity, a “large” effect. However, keep in mind these rules are not absolute. In some fields of research and in relation to some problems, the rules of thumb may be slightly different. You need, in professional practice, to be alert to those nuances by being familiar with the rules that other researchers use in your particular area of work.</p>
<p>How do we write our results up? We could say the following:</p>
<blockquote>
<p>On average, males have a lower score of fear of violent crime (mean = -0.27) than the female group (mean =0.33). Considering a normally distributed score ranging from -2.35 to 3.81, the mean difference of 0.60 suggests a moderate association between gender and fear of violent crime. For example, this association is represented by a medium-sized standardised effect (Cohen’s d=-0.63).</p>
</blockquote>
<p>This is what you would write in your “Findings” section. In your “Conclusions”, you would need to discuss what the theoretical or practical implications of this finding are; connecting it to existing theoretical debates.</p>
</div>
<div id="lab-exercises" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Lab Exercises<a href="regression-i-mean-differences.html#lab-exercises" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Your turn!</strong> In the lab session, using the same data set (the Crime Survey for England and Wales 2007/08, i.e., the <code>csew_0708</code> data.frame), answer the following questions. Note that not all questions necessarily require analysing data in <code>R</code>. After you finish, click on ‘<em>Reveal answer!</em>’ to check your answers.</p>
<p>You want to use the CSEW data to study people’s perceptions about the level of anti-social behaviour in their neighbourhood. The variable <code>tcarea</code> measures that, with higher scores indicating higher levels of perceived anti-social behaviour. Based on social disorganisation theory, you suspect that citizens who live in urban or rural areas have different perceptions. The variable <code>rural2</code> indicates the level of urbanisation of respondents’ area of residence.</p>
<ol style="list-style-type: decimal">
<li>Based on social disorganisation theory, what is your research hypothesis?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>Citizens who reside in urban areas tend to perceive more anti-social behaviour in their neighbourhood than residents of rural areas.</p>
</details>
<ol start="2" style="list-style-type: decimal">
<li>Based on your research hypothesis, what are your dependent and independent variables?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>Dependent variable: perceived levels of anti-social behaviour, i.e., <code>tcarea</code>.</p>
<p>Independent variable: level of urbanisation of respondents’ area of residence, i.e., <code>rural2</code>.</p>
</details>
<ol start="3" style="list-style-type: decimal">
<li>Is your dependent variable numerical or categorical? If categorical, is it binary, ordinal, or multinomial? What about the independent variable?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>The dependent variable, perceived levels of anti-social behaviour in the neighbourhood (<code>tcarea</code>), is a numerical variable.</p>
<p>The independent variable, level of urbanisation of respondents’ area of residence (<code>rural2</code>), is a binary variable.</p>
</details>
<ol start="4" style="list-style-type: decimal">
<li>Using your dependent and independent variables, what is your null hypothesis?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>Null hypothesis: there is no difference in the level of perceived anti-social behaviour in the neighbourhood between residents of urban and rural areas.</p>
</details>
<ol start="5" style="list-style-type: decimal">
<li>How can you assess the association between your dependent and independent variables and test your null hypothesis?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>Given that the dependent variable is numeric and the independent variable is binary, we can test the null hypothesis by estimating a mean difference. If the null hypothesis is true, we would expect the average level of perceived anti-social behaviour in the neighbourhood to be largely the same among both rural and urban residents.</p>
</details>
<ol start="6" style="list-style-type: decimal">
<li>Describe your dependent variable using the appropriate descriptive statistics.</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>Given that <code>tcarea</code> is a numerical variable, we can use the <code>summary()</code> function to describe it.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="regression-i-mean-differences.html#cb357-1" tabindex="-1"></a><span class="fu">summary</span>(csew_0708<span class="sc">$</span>tcarea)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
## -2.6735 -0.7943 -0.0942  0.0303  0.6420  4.1883     677</code></pre>
<p>Perceived anti-social behaviour in the neighbourhood is measured using a scale ranging from -2.67 to 4.19. The mean is 0.03, with a median of -0.09.</p>
</details>
<ol start="7" style="list-style-type: decimal">
<li>Describe your independent variable using the appropriate descriptive statistics.</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>Given that <code>rural2</code> is a binary variable, we can use the <code>table()</code> and the <code>prop.table()</code> functions to describe it.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="regression-i-mean-differences.html#cb359-1" tabindex="-1"></a><span class="fu">table</span>(csew_0708<span class="sc">$</span>rural2)</span></code></pre></div>
<pre><code>## 
## rural urban 
##  2974  8702</code></pre>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="regression-i-mean-differences.html#cb361-1" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(csew_0708<span class="sc">$</span>rural2))</span></code></pre></div>
<pre><code>## 
##     rural     urban 
## 0.2547105 0.7452895</code></pre>
<p>2974 respondents (25.47%) live in rural areas, whereas 8702 respondents (74.53%) live in urban areas.</p>
</details>
<ol start="8" style="list-style-type: decimal">
<li>What is the average score of perceived anti-social behaviour among respondents who live in rural areas? What about respondents who live in urban areas? What is the mean difference?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="regression-i-mean-differences.html#cb363-1" tabindex="-1"></a><span class="co"># Subset the data for respondents living in urban areas</span></span>
<span id="cb363-2"><a href="regression-i-mean-differences.html#cb363-2" tabindex="-1"></a>csew_0708_urban <span class="ot">&lt;-</span> <span class="fu">filter</span>(csew_0708, rural2 <span class="sc">==</span> <span class="st">&quot;urban&quot;</span>)</span>
<span id="cb363-3"><a href="regression-i-mean-differences.html#cb363-3" tabindex="-1"></a></span>
<span id="cb363-4"><a href="regression-i-mean-differences.html#cb363-4" tabindex="-1"></a><span class="co"># Calculate the average perceived ASB in the neighbourhood among urban residents</span></span>
<span id="cb363-5"><a href="regression-i-mean-differences.html#cb363-5" tabindex="-1"></a>mean_urban <span class="ot">&lt;-</span> <span class="fu">mean</span>(csew_0708_urban<span class="sc">$</span>tcarea, <span class="at">na.rm =</span> T)</span>
<span id="cb363-6"><a href="regression-i-mean-differences.html#cb363-6" tabindex="-1"></a></span>
<span id="cb363-7"><a href="regression-i-mean-differences.html#cb363-7" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb363-8"><a href="regression-i-mean-differences.html#cb363-8" tabindex="-1"></a>mean_urban</span></code></pre></div>
<pre><code>## [1] 0.1598183</code></pre>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="regression-i-mean-differences.html#cb365-1" tabindex="-1"></a><span class="co"># Subset the data for respondents living in rural areas</span></span>
<span id="cb365-2"><a href="regression-i-mean-differences.html#cb365-2" tabindex="-1"></a>csew_0708_rural <span class="ot">&lt;-</span> <span class="fu">filter</span>(csew_0708, rural2 <span class="sc">==</span> <span class="st">&quot;rural&quot;</span>)</span>
<span id="cb365-3"><a href="regression-i-mean-differences.html#cb365-3" tabindex="-1"></a></span>
<span id="cb365-4"><a href="regression-i-mean-differences.html#cb365-4" tabindex="-1"></a><span class="co"># Calculate the average perceived ASB in the neighbourhood among rural residents</span></span>
<span id="cb365-5"><a href="regression-i-mean-differences.html#cb365-5" tabindex="-1"></a>mean_rural <span class="ot">&lt;-</span> <span class="fu">mean</span>(csew_0708_rural<span class="sc">$</span>tcarea, <span class="at">na.rm =</span> T)</span>
<span id="cb365-6"><a href="regression-i-mean-differences.html#cb365-6" tabindex="-1"></a></span>
<span id="cb365-7"><a href="regression-i-mean-differences.html#cb365-7" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb365-8"><a href="regression-i-mean-differences.html#cb365-8" tabindex="-1"></a>mean_rural</span></code></pre></div>
<pre><code>## [1] -0.3403847</code></pre>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="regression-i-mean-differences.html#cb367-1" tabindex="-1"></a><span class="co"># Estimate the mean difference</span></span>
<span id="cb367-2"><a href="regression-i-mean-differences.html#cb367-2" tabindex="-1"></a>mean_urban <span class="sc">-</span> mean_rural</span></code></pre></div>
<pre><code>## [1] 0.500203</code></pre>
<p>The average score of perceived anti-social behaviour among respondents who live in urban areas is 0.16, whereas the average score of perceived anti-social behaviour among respondents who live in rural areas is -0.34. The mean difference is 0.5</p>
</details>
<ol start="9" style="list-style-type: decimal">
<li>Let’s build a regression model. Replacing <span class="math inline">\(Y\)</span> with the name of your dependent variable and <span class="math inline">\(X\)</span> with the name of your independent variable, write down the equation with the unknown parameters (i.e., <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>) that you want to estimate. <em>Note: this question does not involve any data analysis</em>.</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p><span class="math display">\[
tcarea = \alpha + \beta \cdot rural2
\]</span></p>
</details>
<ol start="10" style="list-style-type: decimal">
<li>Using the <code>lm()</code> function, estimate the parameters of your linear regression model. Rewrite the equation above, replacing unknown parameters with the estimated parameters.</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="regression-i-mean-differences.html#cb369-1" tabindex="-1"></a><span class="fu">lm</span>(tcarea <span class="sc">~</span> rural2, <span class="at">data =</span> csew_0708)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = tcarea ~ rural2, data = csew_0708)
## 
## Coefficients:
## (Intercept)  rural2urban  
##     -0.3404       0.5002</code></pre>
<p>Based on the results of the linear regression model, we can rewrite the equation in the following way:</p>
<p><span class="math display">\[
tcarea = -0.34 + 0.50 \cdot rural2
\]</span></p>
</details>
<ol start="11" style="list-style-type: decimal">
<li>What does the estimated intercept <span class="math inline">\(\widehat{\alpha}\)</span> represent? What does the estimated slope coefficient <span class="math inline">\(\widehat{\beta}\)</span> represent?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<p>The estimated intercept <span class="math inline">\(\widehat{\alpha}=-0.34\)</span> indicates the average score of perceived anti-social behaviour in the reference group (i.e., when <span class="math inline">\(rural2=0\)</span>). In this case, it indicates that the average perceived anti-social behaviour among rural residents is 0.</p>
<p>The estimated slope coefficient <span class="math inline">\(\widehat{\beta}=0.50\)</span> indicates the mean difference between the comparison and the reference groups. In this case, it indicates that respondents who live in urban areas have, on average, scores of perceived anti-social behaviour in the neighbourhood 0.50 points higher than respondents who live in rural areas.</p>
</details>
<ol start="12" style="list-style-type: decimal">
<li>What do you conclude about the association between your independent and dependent variables? Did you find support for your hypothesis? How strongly associated are the two variables?</li>
</ol>
<details>
<summary>
<i>Reveal answer!</i>
</summary>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="regression-i-mean-differences.html#cb371-1" tabindex="-1"></a><span class="fu">cohen.d</span>(csew_0708<span class="sc">$</span>tcarea <span class="sc">~</span> csew_0708<span class="sc">$</span>rural2)</span></code></pre></div>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: -0.5072798 (medium)
## 95 percent confidence interval:
##      lower      upper 
## -0.5504660 -0.4640936</code></pre>
<p>As hypothesised by social disorganisation theory, on average, residents of urban areas are more exposed to anti-social behaviour in the neighbourhood (mean <span class="math inline">\(=0.16\)</span>) than residents of rural areas (mean <span class="math inline">\(=-0.34\)</span>). Considering a normally distributed score ranging from -2.67 to 4.19, the mean difference of 0.5 suggests a moderate association. For example, this association is represented by a medium-sized standardised effect (Cohen’s d <span class="math inline">\(=-0.51\)</span>).</p>
</details>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Note: While this example examines the fear of crime between men and women, reflecting the focus of much prior research, we acknowledge that gender is not binary and includes transgender, non-binary, and gender-diverse individuals. Their experiences and perceptions of fear may differ and are equally important to consider in criminological research. The binary framing here is intended only to align with the specific scope of prior studies, not to imply that other gender identities are less significant.<a href="regression-i-mean-differences.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="refresher-on-descriptive-statistics-data-carpentry.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-ii-numerical-independent-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
